{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Dense, Flatten, Conv2D, Lambda, Input, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import schedules, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the FER2013 dataset.\n",
    "    \"\"\"\n",
    "file_path = '/kaggle/input/fer2013/fer2013.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "pixels = data['pixels'].tolist()\n",
    "width, height = 48, 48\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = np.asarray([int(pixel) for pixel in pixel_sequence.split(' ')]).reshape(width, height)\n",
    "    face = np.stack((face,)*3, axis=-1)  # Convert to RGB\n",
    "    faces.append(face)\n",
    "faces = np.array(faces)\n",
    "faces = faces.astype('float32') / 255.0\n",
    "\n",
    "emotions = pd.get_dummies(data['emotion']).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * len(faces))\n",
    "input_train, input_test = faces[:train_size], faces[train_size:]\n",
    "target_train, target_test = emotions[:train_size], emotions[train_size:]\n",
    "\n",
    "#     return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "# (input_train, target_train), (input_test, target_test) = (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "input_train = X_train\n",
    "target_train = y_train\n",
    "input_test = X_test\n",
    "target_test = y_test\n",
    "# print(\"\",input_train.shape)\n",
    "\n",
    "width, height, dim = 48, 48, 3\n",
    "num_classes = 7\n",
    "# def preprocess_image(image):\n",
    "#     image = tf.image.resize(image, (48, 48))\n",
    "#     return image\n",
    "\n",
    "# Data augmentation: perform zero padding on datasets\n",
    "# paddings = tf.constant([[0, 0], [4, 4], [4, 4], [0, 0]])\n",
    "# input_train = tf.pad(input_train, paddings, mode=\"CONSTANT\")\n",
    "\n",
    "# Data generator for training data with additional augmentations\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,          # Random rotations\n",
    "    width_shift_range=0.1,      # Random horizontal shifts\n",
    "    height_shift_range=0.1,     # Random vertical shifts\n",
    "    zoom_range=0.1,             # Random zoom\n",
    "    shear_range=0.1,            # Random shear\n",
    "    rescale=1./255\n",
    "#     preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "# Generate training and validation batches\n",
    "train_batches = train_generator.flow(input_train, target_train, batch_size=32, subset=\"training\")\n",
    "validation_batches = train_generator.flow(input_train, target_train, batch_size=32, subset=\"validation\")\n",
    "# batch_x, batch_y = next(train_batches)\n",
    "# print(batch_x.shape)\n",
    "# Data generator for testing data\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Generate test batches\n",
    "test_batches = test_generator.flow(input_test, target_test, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
